import LanguageSwitcher from "@/components/language-switcher"
import { Footer } from "@/components/footer"
import { use, Suspense } from "react"
import { tools, type Language } from "@/config/languages"
import { Metadata } from "next"
import LLMMemoryCalculator from "@/components/llm-memory-calculator"
import { SideNav } from "@/components/side-nav"

export async function generateMetadata({ params }: { params: Promise<{ lang: Language }> }): Promise<Metadata> {
    const { lang } = await params
    const baseUrl = process.env.NEXT_PUBLIC_BASE_URL ||
        (process.env.NODE_ENV === 'development' ? 'http://localhost:3000' : 'https://www.linpp2009.com')
    const path = 'llm-gpu-memory-calculator'

    return {
        title: tools.llmGpuCalculator.metadata.title[lang],
        description: tools.llmGpuCalculator.metadata.description[lang],
        alternates: {
            canonical: `${baseUrl}/${lang}/${path}`,
            languages: {
                'en': `${baseUrl}/en/${path}`,
                'zh': `${baseUrl}/zh/${path}`,
            },
        },
    }
}

export default function LLMGPUMemoryCalculatorPage({
    params,
}: {
    params: Promise<{ lang: Language }>
}) {
    const { lang: language } = use(params)
    const currentPath = `/${language}/llm-gpu-memory-calculator`

    return (
        <div className="min-h-screen flex flex-col">
            <LanguageSwitcher language={language} className="fixed top-4 right-4 z-50" />
            <SideNav language={language} currentPath={currentPath} />

            <main className="pt-20 md:pt-4 md:ml-48 flex-1 flex flex-col items-center p-4 md:p-8">
                <div className="w-full max-w-xl space-y-2 flex-1">
                    <header className="flex flex-col items-center gap-1 mt-8">
                        <h1 className="text-2xl font-bold text-center">
                            {tools.llmGpuCalculator.title[language]}
                        </h1>
                        <p className="text-center text-muted-foreground text-sm">
                            {tools.llmGpuCalculator.description[language]}
                        </p>
                    </header>

                    <Suspense fallback={<div>Loading...</div>}>
                        <LLMMemoryCalculator language={language} />
                    </Suspense>

                    {/* GPUé€‰æ‹©æŒ‡å— - æ›´æœ‰ä»·å€¼çš„å†…å®¹ */}
                    <section className="mt-8 space-y-4">
                        <h2 className="text-lg font-semibold">
                            {language === 'en' ? 'GPU Selection Guide for LLM Deployment' : 'LLMéƒ¨ç½²GPUé€‰æ‹©æŒ‡å—'}
                        </h2>
                        <div className="text-sm text-muted-foreground space-y-3">
                            {language === 'en' ? (
                                <>
                                    <div className="bg-gray-50 p-4 rounded-lg">
                                        <h3 className="font-medium text-gray-900 mb-2">ğŸ’° Budget-Friendly Options (Under $10k)</h3>
                                        <ul className="list-disc pl-5 space-y-1">
                                            <li><strong>RTX 4090 (24GB):</strong> Best for 7B-13B models, single card setup</li>
                                            <li><strong>RTX 3090 (24GB):</strong> Good value for smaller models and experimentation</li>
                                            <li><strong>Multiple RTX 4060 Ti (16GB):</strong> Cost-effective for distributed inference</li>
                                        </ul>
                                    </div>
                                    <div className="bg-gray-50 p-4 rounded-lg">
                                        <h3 className="font-medium text-gray-900 mb-2">ğŸ¢ Enterprise Solutions ($50k+)</h3>
                                        <ul className="list-disc pl-5 space-y-1">
                                            <li><strong>NVIDIA H100 (80GB):</strong> Industry standard for production LLM deployment</li>
                                            <li><strong>NVIDIA A100 (80GB):</strong> Proven reliability, good for 70B+ models</li>
                                            <li><strong>AMD MI300X (192GB):</strong> Highest memory capacity, excellent for largest models</li>
                                        </ul>
                                    </div>
                                    <div className="bg-blue-50 p-4 rounded-lg border border-blue-200">
                                        <h3 className="font-medium text-blue-900 mb-2">âš¡ Pro Tips for Optimization</h3>
                                        <ul className="list-disc pl-5 space-y-1 text-blue-800">
                                            <li><strong>Use FP8/INT8:</strong> Reduce memory usage by 50-75% with minimal quality loss</li>
                                            <li><strong>Consider MoE Models:</strong> Qwen3-235B-A22B offers flagship performance with 4x H100 (vs 10x for DeepSeek-R1)</li>
                                            <li><strong>Model Parallelism:</strong> Split large models across multiple GPUs</li>
                                            <li><strong>Mixed Precision:</strong> Combine FP16 inference with FP32 gradients for training</li>
                                            <li><strong>Memory Mapping:</strong> Use CPU RAM for model storage, GPU for active layers</li>
                                        </ul>
                                    </div>
                                </>
                            ) : (
                                <>
                                    <div className="bg-gray-50 p-4 rounded-lg">
                                        <h3 className="font-medium text-gray-900 mb-2">ğŸ’° é¢„ç®—å‹å¥½é€‰æ‹©ï¼ˆ1ä¸‡ç¾å…ƒä»¥ä¸‹ï¼‰</h3>
                                        <ul className="list-disc pl-5 space-y-1">
                                            <li><strong>RTX 4090 (24GB):</strong> æœ€é€‚åˆ7B-13Bæ¨¡å‹ï¼Œå•å¡é…ç½®</li>
                                            <li><strong>RTX 3090 (24GB):</strong> å°å‹æ¨¡å‹å’Œå®éªŒçš„é«˜æ€§ä»·æ¯”é€‰æ‹©</li>
                                            <li><strong>å¤šå¡RTX 4060 Ti (16GB):</strong> åˆ†å¸ƒå¼æ¨ç†çš„ç»æµé«˜æ•ˆæ–¹æ¡ˆ</li>
                                        </ul>
                                    </div>
                                    <div className="bg-gray-50 p-4 rounded-lg">
                                        <h3 className="font-medium text-gray-900 mb-2">ğŸ¢ ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆï¼ˆ5ä¸‡ç¾å…ƒä»¥ä¸Šï¼‰</h3>
                                        <ul className="list-disc pl-5 space-y-1">
                                            <li><strong>NVIDIA H100 (80GB):</strong> ç”Ÿäº§çº§LLMéƒ¨ç½²çš„è¡Œä¸šæ ‡å‡†</li>
                                            <li><strong>NVIDIA A100 (80GB):</strong> ç»è¿‡éªŒè¯çš„å¯é æ€§ï¼Œé€‚åˆ70B+æ¨¡å‹</li>
                                            <li><strong>AMD MI300X (192GB):</strong> æœ€é«˜æ˜¾å­˜å®¹é‡ï¼Œé€‚åˆæœ€å¤§æ¨¡å‹</li>
                                        </ul>
                                    </div>
                                    <div className="bg-blue-50 p-4 rounded-lg border border-blue-200">
                                        <h3 className="font-medium text-blue-900 mb-2">âš¡ ä¼˜åŒ–ä¸“ä¸šæŠ€å·§</h3>
                                        <ul className="list-disc pl-5 space-y-1 text-blue-800">
                                            <li><strong>ä½¿ç”¨FP8/INT8:</strong> åœ¨è´¨é‡æŸå¤±æœ€å°çš„æƒ…å†µä¸‹å‡å°‘50-75%æ˜¾å­˜ä½¿ç”¨</li>
                                            <li><strong>è€ƒè™‘MoEæ¨¡å‹:</strong> Qwen3-235B-A22Bæä¾›4å—H100æ——èˆ°æ€§èƒ½ï¼ˆå¯¹æ¯”DeepSeek-R1éœ€è¦10å—ï¼‰</li>
                                            <li><strong>æ¨¡å‹å¹¶è¡Œ:</strong> åœ¨å¤šä¸ªGPUä¸Šåˆ†å‰²å¤§å‹æ¨¡å‹</li>
                                            <li><strong>æ··åˆç²¾åº¦:</strong> ç»“åˆFP16æ¨ç†å’ŒFP32æ¢¯åº¦è¿›è¡Œè®­ç»ƒ</li>
                                            <li><strong>å†…å­˜æ˜ å°„:</strong> ä½¿ç”¨CPUå†…å­˜å­˜å‚¨æ¨¡å‹ï¼ŒGPUå¤„ç†æ´»è·ƒå±‚</li>
                                        </ul>
                                    </div>
                                </>
                            )}
                        </div>
                    </section>

                    {/* çƒ­é—¨æ¨¡å‹GPUéœ€æ±‚ */}
                    <section className="mt-8 space-y-4">
                        <h2 className="text-lg font-semibold">
                            {language === 'en' ? 'Popular AI Models GPU Requirements' : 'çƒ­é—¨AIæ¨¡å‹GPUéœ€æ±‚'}
                        </h2>
                        <div className="text-sm text-muted-foreground space-y-4">
                            {language === 'en' ? (
                                <>
                                    <div className="bg-emerald-50 p-4 rounded-lg border border-emerald-200">
                                        <h3 className="font-medium text-emerald-900 mb-2">ğŸ†• Qwen3-235B-A22B GPU Requirements</h3>
                                        <p className="text-emerald-800">
                                            <strong>Qwen3-235B-A22B (235B total, 22B active)</strong> is the latest flagship MoE model. With FP8 precision, you'll need 4x H100 GPUs. This efficient MoE architecture provides competitive performance with DeepSeek-R1 while using 60% less memory.
                                        </p>
                                    </div>
                                    <div className="bg-blue-50 p-4 rounded-lg border border-blue-200">
                                        <h3 className="font-medium text-blue-900 mb-2">DeepSeek R1 GPU Requirements</h3>
                                        <p className="text-blue-800">
                                            <strong>DeepSeek R1 (671B parameters)</strong> requires substantial GPU memory. With FP8 precision, you'll need approximately 10x NVIDIA H100 GPUs or equivalent high-memory configurations for optimal inference performance.
                                        </p>
                                    </div>
                                    <div className="bg-green-50 p-4 rounded-lg border border-green-200">
                                        <h3 className="font-medium text-green-900 mb-2">Llama 3.1 70B GPU Requirements</h3>
                                        <p className="text-green-800">
                                            <strong>Llama 3.1 70B</strong> is more accessible. With FP16 precision, you'll need 2x NVIDIA A100 (80GB) or H100. For consumer hardware, you'll need 7x RTX 4090 cards (24GB each).
                                        </p>
                                    </div>
                                    <div className="bg-purple-50 p-4 rounded-lg border border-purple-200">
                                        <h3 className="font-medium text-purple-900 mb-2">Llama 3.1 405B GPU Requirements</h3>
                                        <p className="text-purple-800">
                                            <strong>Llama 3.1 405B</strong> requires high-end infrastructure. With FP8 precision, you'll need 6x H100 GPUs. With FP16 precision, you'll need 11x A100 GPUs for deployment.
                                        </p>
                                    </div>
                                    <p className="mt-4 text-gray-600">
                                        Use this calculator to get precise memory requirements for your specific use case and budget planning.
                                    </p>
                                </>
                            ) : (
                                <>
                                    <div className="bg-emerald-50 p-4 rounded-lg border border-emerald-200">
                                        <h3 className="font-medium text-emerald-900 mb-2">ğŸ†• Qwen3-235B-A22B GPUéœ€æ±‚</h3>
                                        <p className="text-emerald-800">
                                            <strong>Qwen3-235B-A22Bï¼ˆ235Bæ€»ï¼Œ22Bæ´»è·ƒï¼‰</strong>æ˜¯æœ€æ–°æ——èˆ°MoEæ¨¡å‹ã€‚ä½¿ç”¨FP8ç²¾åº¦ï¼Œæ‚¨åªéœ€è¦4å—H100 GPUï¼è¿™ç§é«˜æ•ˆçš„MoEæ¶æ„æä¾›äº†ä¸DeepSeek-R1ç›¸ç«äº‰çš„æ€§èƒ½ï¼ŒåŒæ—¶å‡å°‘60%çš„å†…å­˜ä½¿ç”¨ã€‚
                                        </p>
                                    </div>
                                    <div className="bg-blue-50 p-4 rounded-lg border border-blue-200">
                                        <h3 className="font-medium text-blue-900 mb-2">DeepSeek R1 GPUéœ€æ±‚</h3>
                                        <p className="text-blue-800">
                                            <strong>DeepSeek R1ï¼ˆ671Bå‚æ•°ï¼‰</strong>éœ€è¦å¤§é‡GPUæ˜¾å­˜ã€‚ä½¿ç”¨FP8ç²¾åº¦ï¼Œæ‚¨éœ€è¦å¤§çº¦8-10å—NVIDIA H100 GPUæˆ–åŒç­‰çš„é«˜æ˜¾å­˜é…ç½®æ¥è·å¾—æœ€ä½³æ¨ç†æ€§èƒ½ã€‚
                                        </p>
                                    </div>
                                    <div className="bg-green-50 p-4 rounded-lg border border-green-200">
                                        <h3 className="font-medium text-green-900 mb-2">Llama 3.1 70B GPUéœ€æ±‚</h3>
                                        <p className="text-green-800">
                                            <strong>Llama 3.1 70B</strong>æ›´å®¹æ˜“éƒ¨ç½²ã€‚ä½¿ç”¨FP16ç²¾åº¦ï¼Œæ‚¨éœ€è¦2å—NVIDIA A100ï¼ˆ80GBï¼‰æˆ–H100ã€‚å¯¹äºæ¶ˆè´¹çº§ç¡¬ä»¶ï¼Œéœ€è¦7å—RTX 4090æ˜¾å¡ï¼ˆæ¯å—24GBï¼‰ã€‚
                                        </p>
                                    </div>
                                    <div className="bg-purple-50 p-4 rounded-lg border border-purple-200">
                                        <h3 className="font-medium text-purple-900 mb-2">Llama 3.1 405B GPUéœ€æ±‚</h3>
                                        <p className="text-purple-800">
                                            <strong>Llama 3.1 405B</strong>éœ€è¦é«˜ç«¯åŸºç¡€è®¾æ–½ã€‚ä½¿ç”¨FP8ç²¾åº¦éœ€è¦6å—H100 GPUã€‚ä½¿ç”¨FP16ç²¾åº¦éœ€è¦11å—A100 GPUè¿›è¡Œéƒ¨ç½²ã€‚
                                        </p>
                                    </div>
                                    <p className="mt-4 text-gray-600">
                                        ä½¿ç”¨è¿™ä¸ªè®¡ç®—å™¨æ¥è·å¾—æ‚¨ç‰¹å®šç”¨ä¾‹çš„ç²¾ç¡®æ˜¾å­˜éœ€æ±‚å’Œé¢„ç®—è§„åˆ’ã€‚
                                    </p>
                                </>
                            )}
                        </div>
                    </section>
                </div>
                <Footer />
            </main>
        </div>
    )
} 